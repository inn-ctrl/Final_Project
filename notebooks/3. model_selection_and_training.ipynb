{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "32ccdab5-6ffa-4226-94db-403da50ac632",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Model imports\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#model dumping\n",
    "from joblib import dump\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73f7a850-0df3-4ecb-b83a-6ea2fb846b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset\n",
    "data = pd.read_csv('../data/data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0d29c3-de76-44da-8699-5c7351c35c05",
   "metadata": {},
   "source": [
    "1. Random Forest classification: Will handle imbalances in left employees without the need to apply other techniques such as oversampling and undersampling\n",
    "2. Metrics: \n",
    "- accuracy\n",
    "- ROC/AUC\n",
    "- precision/recall\n",
    "- f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57aa8542-b63d-440a-8cbe-6a094fffa42d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'rf__max_depth': 10, 'rf__min_samples_leaf': 4, 'rf__min_samples_split': 2, 'rf__n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "#splitting data dataset\n",
    "X = data.drop('Attrition', axis = 1)\n",
    "y = data['Attrition']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42) \n",
    "\n",
    "#model pipeline \n",
    "pipeline = Pipeline([\n",
    "        ('rf', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "## Define the grid of hyperparameters to search\n",
    "param_grid = {\n",
    "    'rf__n_estimators': [100, 200, 300],\n",
    "    'rf__max_depth': [None, 5, 10],\n",
    "    'rf__min_samples_split': [2, 5, 10],\n",
    "    'rf__min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Create the grid search object\n",
    "grid_search = GridSearchCV(pipeline, param_grid=param_grid, cv=5)\n",
    "\n",
    "# Fit the grid search object to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(f\"Best hyperparameters: {best_params}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec77a60-86b1-469b-8f4d-2502573821a4",
   "metadata": {},
   "source": [
    "After splitting the data in train and test splits, we will use RandomClassifier algolrithm. Before using it though, it will be necessary to select the most suitable parameters to so that we come up with the best posible model parameters by using GridSearchCV. Then next, we fit the model to the best performing parameters to come up with the best possible results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e84f196-15b7-412b-bff4-6b4e30fea754",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit on model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "#fit on train\n",
    "result = best_model.fit(X_train, y_train)\n",
    "\n",
    "#y-pred\n",
    "y_pred = best_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c39d02-db25-4fb0-b225-a39686739a68",
   "metadata": {},
   "source": [
    "For future usability, we save our model, trained on this dataset, to be used for future tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23b35bfa-4048-4c59-a2f8-b01a003c9f01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../requirements/best_model.joblib']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder = '../requirements'\n",
    "model_file = os.path.join(folder, 'best_model.joblib')\n",
    "dump(best_model, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6dd9bc83-858d-4e3b-859b-9124079fa3db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8594104308390023\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.98      0.92       380\n",
      "           1       0.47      0.11      0.18        61\n",
      "\n",
      "    accuracy                           0.86       441\n",
      "   macro avg       0.67      0.55      0.55       441\n",
      "weighted avg       0.82      0.86      0.82       441\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#evaluate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "#classification report\n",
    "classification_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(accuracy)\n",
    "print(classification_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d106462-3957-459f-88e6-00056bb09b37",
   "metadata": {},
   "source": [
    "\n",
    "Interpretation:\n",
    "\n",
    "Class 0 (the majority class): The model performs well with high precision (87%) and high recall (98%), indicating that it correctly identifies class 0 instances with high confidence.\n",
    "\n",
    "Class 1 (the minority class): The model performs poorly with low precision (47%) and low recall (11%), indicating that it struggles to correctly identify class 1 instances, often misclassifying them as class 0.\n",
    "\n",
    "Overall: The model's accuracy is 86%, which seems decent, but it is heavily influenced by the high accuracy on class 0 due to its dominance in the dataset. The macro averages (0.55 for precision, recall, and F1-score) reflect the overall performance across both classes, highlighting the imbalance and the model's struggle with class 1.\n",
    "\n",
    "In summary, while the model performs well on class 0, its performance on class 1 is poor, indicating a need for improvement, especially in correctly identifying instances of class 1."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
